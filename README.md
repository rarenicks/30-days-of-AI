
# Motivation :  
Always wanted to add discipline into my learnings and work to boost my productivity in the long run.
However, in any timeboxed event, I often find myself sleeping in the first lap, crawling in the second, running in third and finally sprinting in the last quater to get the things done. As I have practiced this habit over years, so most of the time I complete the work successfully but at the cost of screwed up sleep cycles and mental peace in the end.

So, that's the main motivation of this challenge to not just organize my work pattern but to add consistency and discipline into it, so that I can just jog in the all four quarters of the race and complete it with joy and mental peace. However, I acknowledge this will be challenging and I may or maynot be able to complete this challenge but atleast its a good start in right direction, 

# Completed Milestones : 
- 30 days of AI : June 2021 
- In Progress* : 30 days of Research : March 2022

# 30-days-of-RESERCH - MARCH 2022
To track my daily progress for 30 days AI ML code challenge. 

Find detailed updates in log-march-2022.md

- Day 1/30 : Explored "Computer Aided Methods to Combat COVID-19 Pandemic" collection to find out different methods used by researchers on Covid relief. 
- Day 2/30 : Started reading survey paper on covid detection - "A Comprehensive Survey of COVID-19 Detection Using Medical Images" 
- Day 3/30 : Explored methodology given in the survey paper and created a gist of it. 


--------------------------------------------------------------------------------------------------------------------------------------------------------

# 30-days-of-AI - JUNE 2021
 To track my daily progress for 30 days AI ML code challenge. 

Find detailed updates in log-june-2021.md 

- Day 0/30 : Created this repo and new gpu kernel for anaconda jupyter
- Day 1/30 : Created environment for tic-tae-toc learning agents 
- Day 2/30 : Trained the reinforcement learning agent
- Day 3/30 : Tuned the hypermarkets for the reinforcement agent
- Day 4/30 : Succesfully trained the reinforcement agent with 70% win ratio 
- Day 5/30 : Introduction to deep reinforcement learning. 
- Day 6/30 : Learned about Deep Q learning.
- Day 7/30 : Studied about math behind Deep Q learning and its architectures 
- Day 8/30 : Updated the reinforcement learning agent for tic tae toe to run for 5 Million episodes
- Day 9/30 : Learned about different architectures of DQN 
- Day 10/30 : Read some articles abouts deep learning to understand industry applications.
- Day 11/30 : Started DQN project
- Day 12/30 : Worked on RL-based system for assisting cab drivers
- Day 13/30 : Code for training a deep Q-network
- Day 14/30 : Learned to train double Deep Q network  
- Day 15/30 : Learned about policy based methods in Deep RL 
- Day 16/30 : Created the environment for Cab assisting RL project  
- Day 17/30 : Trained the agent for Cab assisting RL project
- Day 18/30 : Continued the agent training for more episodes and different sets of hyperparameters to get better result
- Day 19/30 : Completed training 10k episodes with 3 Convolution layers 
- Day 20/30 : Revised the concepts of backpropogation 
- Day 21/30 : Learned about actor-critic methods of DQL
- Day 22/30 : Took a step back and again started reading in depth about ANN and its structure 
- Day 23/30 : Learned about Feed forward information flow 
- Day 24/30 : Studied about back propogation flow and weights updation process 
- Day 25/30 : Learned about CNN architecture and understating convolution process
- Day 26/30 : Building CNN in python using keras
- Day 27/30 : Learned about different transfer learning using existing CNN architecture
- Day 28/30 : Studied about Recurrent neural networks and there types
- Day 29/30 : Learned about flavours of RNN - LSTM and GRU 
- Day 30/30 : Building RNN in python using keras